---
title: 'A Simple OpenAI Function Calls Framework'
description: 'Creating a simple framework for developing and testing OpenAI Function Calls'
pubDate: 'Mar 09 2025'
heroImage: '../../assets/images/palmtrees.jpg'
category: 'Tech'
tags: ['AI', 'LLM', 'Python']
---

import eiba_VideoComponent from "../../components/eiba_VideoComponent.astro";

## Creating a simple framework for developing and testing OpenAI Function Calls

I've been experimenting with OpenAI's function calling feature and wanted a way to test my own function calls in a simple and structured manner. I aimed for a lightweight framework that would allow me to define tools and functions separately while letting my chatbot intelligently decide when to call them.  

To make the setup portable and efficient, I decided to build everything around a container image. This approach ensures that:  
- The entire system can be easily spun up in any environment.  
- The actual code remains outside the container, avoiding unnecessary rebuilds during development.  

## The Idea

OpenAI's API platform has its own Playground where you can test function calling, but I wanted a way to be able to test my own local code. The goal was to have a chatbot that:

1. Receives user messages via a web interface.  
2. Sends the messages to OpenAI's API, which decides if a function needs to be called.  
3. Calls the relevant function if needed and returns the result.  
4. Displays everything in a simple front-end.  

To keep things modular, I placed function definitions in a `functions/` folder and tool schemas in a `tools/` folder. This way, adding new functionality is just a matter of dropping in a new Python file.  
## Project Structure

```
app/
│── frontend/
│   └── index.html
│── functions/
│   ├── get_stock_price.py
│   ├── get_weather.py
│── tools/
│   ├── get_stock_price_tool.py
│   ├── get_weather_tool.py
│── main.py
│── requirements.txt
└── Dockerfile
```

## Step-by-Step: Understanding `main.py`

The core of the chatbot lives in `main.py`. Let's break it down step by step.

### 1. Setting Up Flask and OpenAI

```python
import os
import json
import logging
from flask import Flask, request, jsonify, send_from_directory
from openai import OpenAI
import importlib

# Configure logging to print to stdout
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s]: %(message)s", handlers=[logging.StreamHandler()])

app = Flask(__name__)
client = OpenAI()
```

Here, we initialize Flask for our web server, set up logging for better debugging, and create an OpenAI client to handle API requests.


### 2. Loading Functions and Tools Dynamically

```python
# Directories for tools and functions
TOOLS_DIR = os.path.join(os.path.dirname(__file__), "tools")
FUNCTIONS_DIR = os.path.join(os.path.dirname(__file__), "functions")

def load_modules(directory):
    """Dynamically loads all Python modules in a given directory."""
    modules = {}
    for filename in os.listdir(directory):
        if filename.endswith('.py') and filename != '__init__.py':
            module_name = f"{directory.split(os.sep)[-1]}.{filename[:-3]}"
            module = importlib.import_module(module_name)
            for attr in dir(module):
                obj = getattr(module, attr)
                if callable(obj):
                    modules[obj.__name__] = obj
    return modules

# Load functions and tools
functions = load_modules(FUNCTIONS_DIR)
tools_definitions = load_modules(TOOLS_DIR)
tools = [tool() for tool in tools_definitions.values()]
```

This dynamically imports all Python scripts inside `functions/` and `tools/`, making it easy to extend the chatbot.


### 3. Handling Chat Requests


```python
@app.route("/chat", methods=["POST"])
def chat():
    data = request.get_json()
    user_message = data.get("message", "")

    messages = [
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": user_message}
    ]

    # Call OpenAI's chat completion with function calling
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        tools=tools,
        tool_choice="auto"
    )

    response_message = response.choices[0].message
```

This function receives user input and sends it to OpenAI's API.
If OpenAI decides to call a function, we execute it and append the result to the chat history.


### 4. Handling Function Calls

```python
  # Check if the model decided to call a function
  if response_message.tool_calls:
      tool_calls_responses = []
      for tool_call in response_message.tool_calls:
          function_name = tool_call.function.name
          function_args = json.loads(tool_call.function.arguments)

          logging.info(f"Model called function: {function_name} with args: {function_args}")  # Log function call

          if function_name in functions:
              function_response = functions[function_name](**function_args)
              logging.info(f"Function response: {function_response}")  # Log function response
          else:
              function_response = {"error": f"Function '{function_name}' is not recognized"}

          tool_calls_responses.append({
              "role": "tool",
              "tool_call_id": tool_call.id,
              "content": json.dumps(function_response)
          })

      messages.append(response_message)
      messages.extend(tool_calls_responses)

      second_response = client.chat.completions.create(
          model="gpt-4o-mini",
          messages=messages
      )
      final_text = second_response.choices[0].message.content
  else:
      final_text = response_message.content

  logging.info(f"Final response to user: {final_text}")  # Log chatbot's response

  return jsonify({"reply": final_text})
```

After executing the function, we ask OpenAI for a final response.

### 5. Serving the Frontend

```python
@app.route("/")
def serve_index():
    return send_from_directory(os.path.join(os.path.dirname(__file__), "frontend"), "index.html")
```

This serves the chatbot's front-end where we can test the functions.

### 6. Running the App

```python
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
```

This starts the Flask server, exposing it on port 5000.

## Running the App in Docker

To make deployment easy, I created a `Dockerfile`:

```dockerfile
FROM python:3.9-slim

# Set the working directory in the container
WORKDIR /app

# Copy requirements and install them
COPY app/requirements.txt /app/requirements.txt
RUN pip install --no-cache-dir -r /app/requirements.txt

# Expose port 5000 for the Flask app
EXPOSE 5000

# By default, run the Flask app
CMD ["python", "/app/main.py"]
```

The container consists of a lightweight Python image and a requirements.txt file that includes the modules that our app requires.
We then run pip install pointing to our requirements.txt file, which installs the required modules in the container.

#### requirements.txt
```bash
Flask
openai
requests
```

## The Frontend

I then made a simple HTML page (`frontend/index.html`) where users can chat with the bot:

<details>
  <summary>index.html</summary>

  ```html
  <!DOCTYPE html>
  <html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0" />
    <title>Chatbot</title>
    <style>
      * {
        margin: 0; 
        padding: 0; 
        box-sizing: border-box;
      }
      html, body {
        height: 100%;
        font-family: 'Helvetica Neue', Arial, sans-serif;
        background-color: #f0f2f5;
      }
      body {
        display: flex;
        align-items: center;
        justify-content: center;
      }

      .chat-container {
        display: flex;
        flex-direction: column;
        width: 90%;
        max-width: 600px;
        height: 80vh;
        background-color: #fff;
        border-radius: 8px;
        box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        overflow: hidden;
      }

      .chat-header {
        background-color: #3498db;
        color: #fff;
        padding: 16px;
        font-size: 20px;
        font-weight: bold;
        text-align: center;
      }

      #chat-log {
        flex: 1;
        display: flex;
        flex-direction: column-reverse; /* Messages appear at the bottom */
        padding: 16px;
        overflow-y: auto;
        background: #fafafa;
      }
      #chat-log::-webkit-scrollbar {
        width: 8px;
      }
      #chat-log::-webkit-scrollbar-track {
        background: #eef1f5;
      }
      #chat-log::-webkit-scrollbar-thumb {
        background-color: #3498db;
        border-radius: 4px;
      }
      #chat-log {
        scrollbar-width: thin;
        scrollbar-color: #3498db #eef1f5;
      }

      .message {
        display: inline-block;
        clear: both;
        margin: 10px 0;
        padding: 10px 14px;
        border-radius: 16px;
        max-width: 70%;
        line-height: 1.4;
        word-wrap: break-word;
      }
      .user-message {
        background-color: #3498db;
        color: #fff;
        align-self: flex-end;
        border-bottom-right-radius: 2px; 
      }
      .bot-message {
        background-color: #ecf0f1;
        color: #2c3e50;
        align-self: flex-start;
        border-bottom-left-radius: 2px; 
      }

      .input-container {
        display: flex;
        border-top: 1px solid #ddd;
        padding: 12px;
        background-color: #fafafa;
      }
      .input-container input {
        flex: 1;
        border: 1px solid #ccc;
        border-radius: 4px;
        font-size: 16px;
        padding: 10px;
        outline: none;
      }
      .input-container button {
        margin-left: 8px;
        border: none;
        border-radius: 4px;
        background-color: #3498db;
        color: #fff;
        font-size: 16px;
        padding: 0 18px;
        cursor: pointer;
      }
      .input-container button:hover {
        background-color: #2c80b4;
      }
    </style>
  </head>
  <body>
    <div class="chat-container">
      <div class="chat-header">Chatbot</div>

      <div id="chat-log"></div>

      <div class="input-container">
        <input 
          type="text" 
          id="user-input" 
          placeholder="Type your message..." 
          onkeypress="handleKeyPress(event)"
        />
        <button onclick="sendMessage()">Send</button>
      </div>
    </div>

    <script>
      async function sendMessage() {
        const chatLog = document.getElementById("chat-log");
        const userInput = document.getElementById("user-input");
        const message = userInput.value.trim();

        if (!message) return;

        addToChat("User", message, "user-message");
        userInput.value = "";

        try {
          const response = await fetch("/chat", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ message: message })
          });
          const data = await response.json();
          addToChat("Bot", data.reply, "bot-message");
        } catch (err) {
          addToChat("Bot", "Error: " + err.toString(), "bot-message");
        }
      }

      function addToChat(role, text, className) {
        const chatLog = document.getElementById("chat-log");

        // Create the message element
        const msgDiv = document.createElement("div");
        msgDiv.classList.add("message", className);
        msgDiv.innerHTML = `<strong>${role}:</strong> ${text}`;

        // Insert message at the beginning (so new messages are at the bottom)
        chatLog.prepend(msgDiv);
      }

      function handleKeyPress(event) {
        if (event.key === "Enter") {
          sendMessage();
        }
      }
    </script>
  </body>
  </html>
```
</details>


Build and run the container:

```sh
docker build -t my-chatbot .
docker run -p 5000:5000 e OPENAI_API_KEY=<YOUR_OPENAI_API_KEY> -v $(pwd)/app:/app my-chatbot
```

### 7. Example Functions scripts

Each function is defined in its own script file and loaded dynamically.

<details>
  <summary>get_weather()</summary>

```python
import requests

def get_weather(location: str) -> str:
    """
    Fetches weather information for the given location.
    
    Args:
        location (str): The name of the city to fetch weather data for.
    
    Returns:
        str: A string describing the weather conditions.
    """
    
    api_url = f"https://wttr.in/{location}?format=%C+%t"
    try:
        response = requests.get(api_url)
        if response.status_code == 200:
            return f"Weather in {location}: {response.text}"
        else:
            return f"Could not retrieve weather for {location}."
    except Exception as e:
        return f"Error fetching weather: {str(e)}"

```
</details>

<details>
  <summary>get_stock_price()</summary>

```python
def get_stock_price(ticker: str) -> str:
  """
  Mock function to simulate fetching stock price information for the given ticker symbol.
  
  Args:
      ticker (str): The stock ticker symbol to fetch price data for.
  
  Returns:
      str: A string describing the stock price.
  """
  mock_responses = {
      "AAPL": "Stock price for AAPL: $150.00",
      "GOOGL": "Stock price for GOOGL: $2800.00",
      "AMZN": "Stock price for AMZN: $3400.00"
  }
  return mock_responses.get(ticker, f"Stock price for {ticker}: Data not available")
```
</details>

### 8. Example Tools scripts

Each tool is defined in its own script file and loaded dynamically.

<details>
  <summary>get_weather_tool()</summary>

```python
def get_weather_tool():
    """
    Defines the tool schema for fetching weather information.
    """
    return {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "Retrieve weather information for a specified location.",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "Name of the city to get weather information for."
                    }
                },
                "required": ["location"],
                "additionalProperties": False
            },
            "strict": True
        }
    }
```
</details>

<details>
  <summary>get_stock_price_tool()</summary>
```python
def get_stock_price_tool():
    """
    Tool schema for fetching stock price information.
    """
    return {
        "type": "function",
        "function": {
            "name": "get_stock_price",
            "description": "Fetches stock price information for the given ticker symbol.",
            "parameters": {
                "type": "object",
                "properties": {
                    "ticker": {"type": "string", "description": "The stock ticker symbol to fetch price data for."}
                },
                "required": ["ticker"]
            }
        }
    }
```
</details>


## Conclusion

This setup lets me quickly test new function calls, and the modular structure makes it easy to add new functions and tools. If I want to extend it, I can just drop in new `.py` files in `functions/` and `tools/`, and the chatbot will automatically pick them up.

And the result:

<div style="display: flex; justify-content: center; align-items: center;">
  <video autoplay loop muted playsinline style="height: auto; width: 350px; max-width: 100%;">
    <source src="/videos/chatvideo.webm" type="video/webm"/>
    Your browser does not support the video tag.
  </video>
</div>

